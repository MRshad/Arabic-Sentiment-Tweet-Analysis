{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 169: expected 1 fields, saw 4\\nSkipping line 266: expected 1 fields, saw 2\\nSkipping line 314: expected 1 fields, saw 2\\nSkipping line 361: expected 1 fields, saw 2\\nSkipping line 388: expected 1 fields, saw 2\\nSkipping line 796: expected 1 fields, saw 2\\nSkipping line 873: expected 1 fields, saw 3\\n'\n"
     ]
    }
   ],
   "source": [
    "positive=pd.read_csv(\"tweetsp.csv\", sep=\",\",error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 13: expected 1 fields, saw 4\\nSkipping line 23: expected 1 fields, saw 5\\nSkipping line 25: expected 1 fields, saw 2\\nSkipping line 64: expected 1 fields, saw 4\\nSkipping line 68: expected 1 fields, saw 4\\nSkipping line 82: expected 1 fields, saw 4\\nSkipping line 94: expected 1 fields, saw 5\\nSkipping line 96: expected 1 fields, saw 2\\nSkipping line 138: expected 1 fields, saw 9\\nSkipping line 150: expected 1 fields, saw 3\\nSkipping line 163: expected 1 fields, saw 9\\nSkipping line 229: expected 1 fields, saw 2\\nSkipping line 280: expected 1 fields, saw 2\\nSkipping line 365: expected 1 fields, saw 2\\nSkipping line 463: expected 1 fields, saw 2\\nSkipping line 565: expected 1 fields, saw 3\\nSkipping line 566: expected 1 fields, saw 3\\nSkipping line 606: expected 1 fields, saw 2\\nSkipping line 690: expected 1 fields, saw 2\\nSkipping line 831: expected 1 fields, saw 3\\nSkipping line 967: expected 1 fields, saw 2\\n'\n"
     ]
    }
   ],
   "source": [
    "negative=pd.read_csv(\"tweetsn.csv\", sep=\",\",error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_neg= pd.Series(0,index=range(negative.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_pos= pd.Series(1,index=range(positive.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "5      1\n",
       "6      1\n",
       "7      1\n",
       "8      1\n",
       "9      1\n",
       "10     1\n",
       "11     1\n",
       "12     1\n",
       "13     1\n",
       "14     1\n",
       "15     1\n",
       "16     1\n",
       "17     1\n",
       "18     1\n",
       "19     1\n",
       "20     1\n",
       "21     1\n",
       "22     1\n",
       "23     1\n",
       "24     1\n",
       "25     1\n",
       "26     1\n",
       "27     1\n",
       "28     1\n",
       "29     1\n",
       "      ..\n",
       "912    0\n",
       "913    0\n",
       "914    0\n",
       "915    0\n",
       "916    0\n",
       "917    0\n",
       "918    0\n",
       "919    0\n",
       "920    0\n",
       "921    0\n",
       "922    0\n",
       "923    0\n",
       "924    0\n",
       "925    0\n",
       "926    0\n",
       "927    0\n",
       "928    0\n",
       "929    0\n",
       "930    0\n",
       "931    0\n",
       "932    0\n",
       "933    0\n",
       "934    0\n",
       "935    0\n",
       "936    0\n",
       "937    0\n",
       "938    0\n",
       "939    0\n",
       "940    0\n",
       "941    0\n",
       "Length: 1935, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=[label_pos,label_neg]\n",
    "y = pd.concat(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=[positive,negative]\n",
    "x = pd.concat(x)\n",
    "x=x['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=2, ngram_range=(1, 2),  strip_accents='unicode' ,   norm='l2')\n",
    "X = vectorizer.fit_transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print (\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Print and return results\n",
    "    print (\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    return f1_score(target.values, y_pred, pos_label=1)\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print (\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, X_train.shape[0]))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print (\"F1 score for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "    print (\"F1 score for test set: {:.4f}.\".format(predict_labels(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB\n",
      "NB -100\n",
      "Training a MultinomialNB using a training set size of 1000. . .\n",
      "Trained model in 0.0100 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for training set: 0.9551.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.8468.\n",
      "NB -all\n",
      "Training a MultinomialNB using a training set size of 1296. . .\n",
      "Trained model in 0.0000 seconds\n",
      "Made predictions in 0.0100 seconds.\n",
      "F1 score for training set: 0.9488.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.8642.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import the three supervised learning models from sklearn\n",
    "# from sklearn import model_A\n",
    "# from sklearn import model_B\n",
    "# from sklearn import model_C\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "# TODO: Initialize the three models\n",
    "clf_nbays = MultinomialNB()\n",
    "clf_DT = tree.DecisionTreeClassifier(max_depth=500)\n",
    "clf_svm = SVC()\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Set up the training set sizes\n",
    "X_train_100 = X_train[:1000]\n",
    "y_train_100 = y_train[:1000]\n",
    "\n",
    "\n",
    "X_train_all = X_train\n",
    "y_train_all = y_train\n",
    "\n",
    "# TODO: Execute the 'train_predict' function for each classifier and each training set size\n",
    "print( \"NB\")\n",
    "print( \"NB -100\")\n",
    "train_predict(clf_nbays, X_train_100, y_train_100, X_test, y_test)\n",
    "\n",
    "print( \"NB -all\")\n",
    "train_predict(clf_nbays, X_train_all, y_train_all, X_test, y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT\n",
      "DT -100\n",
      "Training a DecisionTreeClassifier using a training set size of 1000. . .\n",
      "Trained model in 0.3300 seconds\n",
      "Made predictions in 0.0200 seconds.\n",
      "F1 score for training set: 0.9875.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.7643.\n",
      "DT -all\n",
      "Training a DecisionTreeClassifier using a training set size of 1296. . .\n",
      "Trained model in 0.1300 seconds\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for training set: 0.9879.\n",
      "Made predictions in 0.0000 seconds.\n",
      "F1 score for test set: 0.7770.\n"
     ]
    }
   ],
   "source": [
    "print( \"DT\")\n",
    "print( \"DT -100\")\n",
    "train_predict(clf_DT, X_train_100, y_train_100, X_test, y_test)\n",
    "\n",
    "print( \"DT -all\")\n",
    "train_predict(clf_DT, X_train_all, y_train_all, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "SVM -100\n",
      "Training a SVC using a training set size of 1000. . .\n",
      "Trained model in 0.1200 seconds\n",
      "Made predictions in 0.0800 seconds.\n",
      "F1 score for training set: 0.6894.\n",
      "Made predictions in 0.0600 seconds.\n",
      "F1 score for test set: 0.6770.\n",
      "SVM-300\n",
      "Training a SVC using a training set size of 1296. . .\n",
      "Trained model in 0.1600 seconds\n",
      "Made predictions in 0.1500 seconds.\n",
      "F1 score for training set: 0.6789.\n",
      "Made predictions in 0.0700 seconds.\n",
      "F1 score for test set: 0.6770.\n"
     ]
    }
   ],
   "source": [
    "print( \"SVM\")\n",
    "print( \"SVM -100\")\n",
    "train_predict(clf_svm, X_train_100, y_train_100, X_test, y_test)\n",
    "\n",
    "print( \"SVM-300\")\n",
    "train_predict(clf_svm, X_train_all, y_train_all, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X, y)\n",
    "y_nbays_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.82731959,  0.78092784,  0.7622739 ,  0.86528497,  0.88601036])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MRshad\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "clf = SGDClassifier(alpha=.0001, n_iter=70).fit(X, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.73969072,  0.79639175,  0.77777778,  0.80569948,  0.82124352])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm_classifier = LinearSVC().fit(X, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7371134 ,  0.79896907,  0.7751938 ,  0.80829016,  0.82124352])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_clf = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)\n",
    "y_rdm_forest_pred = RF_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.88      0.82       312\n",
      "          1       0.86      0.74      0.80       327\n",
      "\n",
      "avg / total       0.82      0.81      0.81       639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (classification_report(y_test, y_rdm_forest_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[274  38]\n",
      " [ 84 243]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_rdm_forest_pred)\n",
    "print (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1528)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "y_nbays_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.79      0.84       312\n",
      "          1       0.82      0.91      0.86       327\n",
      "\n",
      "avg / total       0.86      0.85      0.85       639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( classification_report(y_test, y_nbays_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
